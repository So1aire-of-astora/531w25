---
title: "Lim & Zohren, 2021"
date: "Feb 13, 2025"
output:
  ioslides_presentation:
    smaller: no
    widescreen: true
    transition: "faster" 
---

## Impact

* cited 1550 times

* Philosophical Transactions A (impact factor: 4.3)

* This is a review paper

## Insights

* CNN is like an AR model: finite number of lags of previous data.

* RNN is like an SSM


## The M4 Forecasting Competition

* Hyndman R. (2020). A brief history of forecasting competitions. Int. J. Forecast. 36, 7–14. (doi:10.1016/j.ijforecast.2019.03.015)

* Makridakis, S., Spiliotis, E., & Assimakopoulos, V. (2020). The M4 Competition: 100,000 time series and 61 forecasting methods. International Journal of Forecasting, 36, 54-74. (https://doi.org/10.1016/j.ijforecast.2019.04.014)

* **The clear winner of the M4 forecasting competition**.\
Smyl, S. (2020). A hybrid method of exponential smoothing and recurrent neural networks for time series forecasting. International Journal of Forecasting, 36, 75–85. (https://doi.org/10.1016/j.ijforecast.2019.03.017)

## Smyl (2020) and LSTM

* Uses a combination of exponential smoothing and long short-term memory (LSTM) recurrent neural net (RNN) methods.

* LSTM was state-of-the-art from 2015-2020: Google translate, Apple's Siri, Amazon's Alexa, Facebook translate, OpenAI, DeepMind.

* Achieved prominence by winning a handwriting recognition competition in 2009 (https://en.wikipedia.org/wiki/Long_short-term_memory).

* LSTM Largely addresses the vanishing gradient problem; can have the exploding gradient problem

## Forecasting and science

* How is forecasting related and unrelated to developing useful understanding?


